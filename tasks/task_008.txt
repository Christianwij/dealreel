# Task ID: 8
# Title: Develop AI Video Generation System
# Status: pending
# Dependencies: 3, 7
# Priority: high
# Description: Create the video generation pipeline using D-ID for avatar narration and Remotion for visual composition, producing 2-5 minute MP4 briefings.
# Details:
1. Set up D-ID API integration:
```typescript
const generateNarration = async (script, section) => {
  const response = await fetch('https://api.d-id.com/talks', {
    method: 'POST',
    headers: {
      'Authorization': `Basic ${process.env.DID_API_KEY}`,
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      script: {
        type: 'text',
        input: script[section],
        provider: {
          type: 'microsoft',
          voice_id: 'en-US-GuyNeural'
        }
      },
      config: {
        fluent: true,
        pad_audio: 0
      },
      source_url: 'https://create-images-results.d-id.com/DefaultPresenters/Noelle_f_ca_straightface_v3/image.jpeg'
    })
  });
  
  const data = await response.json();
  return data.id; // Returns talk ID for status checking
};

const getNarrationResult = async (talkId) => {
  const response = await fetch(`https://api.d-id.com/talks/${talkId}`, {
    headers: {
      'Authorization': `Basic ${process.env.DID_API_KEY}`
    }
  });
  
  const data = await response.json();
  return data;
};
```

2. Set up Remotion for video composition:
```bash
npm install remotion @remotion/cli
```

3. Create Remotion composition components:
```typescript
// components/remotion/BriefingVideo.tsx
import { Composition } from 'remotion';
import { BriefingComposition } from './BriefingComposition';

export const RemotionVideo: React.FC = () => {
  return (
    <Composition
      id="BriefingVideo"
      component={BriefingComposition}
      durationInFrames={30 * 60 * 5} // 5 minutes max at 30fps
      fps={30}
      width={1920}
      height={1080}
    />
  );
};

// components/remotion/BriefingComposition.tsx
import { AbsoluteFill, Audio, Sequence } from 'remotion';
import { Intro } from './sections/Intro';
import { BusinessModel } from './sections/BusinessModel';
import { Metrics } from './sections/Metrics';
import { Risks } from './sections/Risks';
import { Summary } from './sections/Summary';

export const BriefingComposition = ({ script, audioSources, metrics, companyInfo }) => {
  // Calculate section durations based on audio length
  const introDuration = calculateDurationInFrames(audioSources.intro);
  const businessModelDuration = calculateDurationInFrames(audioSources.businessModel);
  // ... other durations
  
  return (
    <AbsoluteFill style={{ backgroundColor: '#141414' }}>
      <Sequence from={0} durationInFrames={introDuration}>
        <Audio src={audioSources.intro} />
        <Intro script={script.introduction} companyInfo={companyInfo} />
      </Sequence>
      
      <Sequence from={introDuration} durationInFrames={businessModelDuration}>
        <Audio src={audioSources.businessModel} />
        <BusinessModel script={script.businessModel} />
      </Sequence>
      
      {/* Other sequences */}
    </AbsoluteFill>
  );
};
```

4. Implement video rendering function:
```typescript
const renderVideo = async (briefingId) => {
  // Get briefing data
  const { data: briefing } = await supabase
    .from('briefings')
    .select('*, uploads(*)')
    .eq('id', briefingId)
    .single();
    
  // Generate narration for each section
  const narrationIds = {};
  for (const section of Object.keys(briefing.script)) {
    narrationIds[section] = await generateNarration(briefing.script, section);
  }
  
  // Wait for all narrations to complete
  const audioSources = {};
  for (const [section, id] of Object.entries(narrationIds)) {
    let result;
    do {
      result = await getNarrationResult(id);
      if (result.status !== 'done') {
        await new Promise(resolve => setTimeout(resolve, 1000));
      }
    } while (result.status !== 'done');
    
    audioSources[section] = result.result_url;
  }
  
  // Render video with Remotion
  const outputPath = `/tmp/${briefingId}.mp4`;
  await renderMedia({
    composition: 'BriefingVideo',
    serveUrl: process.env.REMOTION_SERVE_URL,
    outputLocation: outputPath,
    inputProps: {
      script: briefing.script,
      audioSources,
      metrics: extractMetrics(briefing),
      companyInfo: extractCompanyInfo(briefing)
    },
  });
  
  // Upload to Supabase Storage
  const { data, error } = await supabase.storage
    .from('videos')
    .upload(`${briefing.user_id}/${briefingId}.mp4`, fs.createReadStream(outputPath));
    
  if (error) throw error;
  
  // Update briefing record
  await supabase
    .from('briefings')
    .update({
      video_url: data.path,
      status: 'completed'
    })
    .eq('id', briefingId);
    
  // Clean up temp file
  fs.unlinkSync(outputPath);
};
```

5. Create visual components for each section type
6. Implement metrics visualization and callouts
7. Add branding and transition animations

# Test Strategy:
1. Test D-ID API integration with sample scripts
2. Validate Remotion rendering with test compositions
3. Test end-to-end video generation pipeline
4. Benchmark video rendering performance
5. Verify video quality and synchronization
6. Test error handling and recovery
7. Validate storage and retrieval of generated videos
